{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luize\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8322 - loss: 0.4017 - val_accuracy: 0.8966 - val_loss: 0.2441\n",
      "Epoch 2/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9173 - loss: 0.2092 - val_accuracy: 0.9292 - val_loss: 0.1815\n",
      "Epoch 3/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.1796 - val_accuracy: 0.9300 - val_loss: 0.1694\n",
      "Epoch 4/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 988us/step - accuracy: 0.9335 - loss: 0.1633 - val_accuracy: 0.9349 - val_loss: 0.1577\n",
      "Epoch 5/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9367 - loss: 0.1550 - val_accuracy: 0.9361 - val_loss: 0.1525\n",
      "Epoch 6/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9379 - loss: 0.1516 - val_accuracy: 0.9407 - val_loss: 0.1447\n",
      "Epoch 7/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9392 - loss: 0.1447 - val_accuracy: 0.9352 - val_loss: 0.1551\n",
      "Epoch 8/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9404 - loss: 0.1422 - val_accuracy: 0.9379 - val_loss: 0.1510\n",
      "Epoch 9/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9426 - loss: 0.1379 - val_accuracy: 0.9422 - val_loss: 0.1363\n",
      "Epoch 10/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9415 - loss: 0.1367 - val_accuracy: 0.9434 - val_loss: 0.1356\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 671us/step\n",
      "Acurácia: 0.9450568114268245\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_train = pd.read_csv('train_normalized.csv')\n",
    "df_test = pd.read_csv('train_normalized.csv')\n",
    "\n",
    "# Substitua esta parte pelo seu próprio código de preparação dos dados\n",
    "X_train = df_train.drop(columns=['satisfaction']).values\n",
    "y_train = df_train['satisfaction'].values\n",
    "X_test = df_test.drop(columns=['satisfaction']).values\n",
    "y_test = df_test['satisfaction'].values\n",
    "\n",
    "# Dividir o conjunto de treino em treino e validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Definindo a arquitetura da MLP\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=1, activation='sigmoid'))  # Camada de saída para classificação binária\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliar o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luize\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8435 - loss: 0.3800 - val_accuracy: 0.9129 - val_loss: 0.2131\n",
      "Epoch 2/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9159 - loss: 0.2068 - val_accuracy: 0.9278 - val_loss: 0.1785\n",
      "Epoch 3/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.1761 - val_accuracy: 0.9311 - val_loss: 0.1717\n",
      "Epoch 4/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 999us/step - accuracy: 0.9352 - loss: 0.1587 - val_accuracy: 0.9339 - val_loss: 0.1540\n",
      "Epoch 5/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9405 - loss: 0.1462 - val_accuracy: 0.9370 - val_loss: 0.1490\n",
      "Epoch 6/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.1406 - val_accuracy: 0.9430 - val_loss: 0.1358\n",
      "Epoch 7/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9414 - loss: 0.1381 - val_accuracy: 0.9422 - val_loss: 0.1438\n",
      "Epoch 8/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.1329 - val_accuracy: 0.9421 - val_loss: 0.1412\n",
      "Epoch 9/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 995us/step - accuracy: 0.9457 - loss: 0.1279 - val_accuracy: 0.9461 - val_loss: 0.1278\n",
      "Epoch 10/10\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 996us/step - accuracy: 0.9461 - loss: 0.1271 - val_accuracy: 0.9469 - val_loss: 0.1250\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 693us/step\n",
      "Acurácia: 0.9490055877307699\n"
     ]
    }
   ],
   "source": [
    "# Definindo a arquitetura da MLP\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=1, activation='sigmoid'))  # Camada de saída para classificação binária\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliar o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos tentar usar a learning rate de 0.001 e 20 epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luize\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8560 - loss: 0.3609 - val_accuracy: 0.9169 - val_loss: 0.2038\n",
      "Epoch 2/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9211 - loss: 0.1996 - val_accuracy: 0.9282 - val_loss: 0.1758\n",
      "Epoch 3/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9313 - loss: 0.1724 - val_accuracy: 0.9292 - val_loss: 0.1650\n",
      "Epoch 4/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9352 - loss: 0.1588 - val_accuracy: 0.9395 - val_loss: 0.1493\n",
      "Epoch 5/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9397 - loss: 0.1463 - val_accuracy: 0.9400 - val_loss: 0.1420\n",
      "Epoch 6/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9405 - loss: 0.1430 - val_accuracy: 0.9403 - val_loss: 0.1498\n",
      "Epoch 7/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.1379 - val_accuracy: 0.9384 - val_loss: 0.1417\n",
      "Epoch 8/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.1324 - val_accuracy: 0.9452 - val_loss: 0.1302\n",
      "Epoch 9/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.1303 - val_accuracy: 0.9464 - val_loss: 0.1312\n",
      "Epoch 10/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1273 - val_accuracy: 0.9449 - val_loss: 0.1294\n",
      "Epoch 11/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9465 - loss: 0.1253 - val_accuracy: 0.9467 - val_loss: 0.1250\n",
      "Epoch 12/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9490 - loss: 0.1237 - val_accuracy: 0.9436 - val_loss: 0.1320\n",
      "Epoch 13/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9484 - loss: 0.1193 - val_accuracy: 0.9478 - val_loss: 0.1266\n",
      "Epoch 14/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1195 - val_accuracy: 0.9471 - val_loss: 0.1262\n",
      "Epoch 15/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1158 - val_accuracy: 0.9450 - val_loss: 0.1312\n",
      "Epoch 16/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9503 - loss: 0.1165 - val_accuracy: 0.9426 - val_loss: 0.1220\n",
      "Epoch 17/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1155 - val_accuracy: 0.9492 - val_loss: 0.1151\n",
      "Epoch 18/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1128 - val_accuracy: 0.9474 - val_loss: 0.1211\n",
      "Epoch 19/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1128 - val_accuracy: 0.9509 - val_loss: 0.1175\n",
      "Epoch 20/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1104 - val_accuracy: 0.9510 - val_loss: 0.1121\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 705us/step\n",
      "Acurácia: 0.9540498310093581\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# Definindo um otimizador com learning rate específica\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Criando o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo com o otimizador personalizado\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliando o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos tentar o mesmo exemplo com menos camadas escondidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luize\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8317 - loss: 0.3953 - val_accuracy: 0.9100 - val_loss: 0.2276\n",
      "Epoch 2/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9168 - loss: 0.2103 - val_accuracy: 0.9241 - val_loss: 0.1895\n",
      "Epoch 3/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9255 - loss: 0.1884 - val_accuracy: 0.9322 - val_loss: 0.1708\n",
      "Epoch 4/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9330 - loss: 0.1680 - val_accuracy: 0.9320 - val_loss: 0.1631\n",
      "Epoch 5/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9359 - loss: 0.1579 - val_accuracy: 0.9383 - val_loss: 0.1500\n",
      "Epoch 6/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9389 - loss: 0.1495 - val_accuracy: 0.9366 - val_loss: 0.1479\n",
      "Epoch 7/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9397 - loss: 0.1460 - val_accuracy: 0.9418 - val_loss: 0.1411\n",
      "Epoch 8/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.1397 - val_accuracy: 0.9408 - val_loss: 0.1363\n",
      "Epoch 9/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.1356 - val_accuracy: 0.9443 - val_loss: 0.1309\n",
      "Epoch 10/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 974us/step - accuracy: 0.9437 - loss: 0.1345 - val_accuracy: 0.9401 - val_loss: 0.1340\n",
      "Epoch 11/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 938us/step - accuracy: 0.9446 - loss: 0.1307 - val_accuracy: 0.9459 - val_loss: 0.1296\n",
      "Epoch 12/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 935us/step - accuracy: 0.9479 - loss: 0.1261 - val_accuracy: 0.9371 - val_loss: 0.1377\n",
      "Epoch 13/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 944us/step - accuracy: 0.9439 - loss: 0.1288 - val_accuracy: 0.9471 - val_loss: 0.1273\n",
      "Epoch 14/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.1257 - val_accuracy: 0.9464 - val_loss: 0.1243\n",
      "Epoch 15/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9484 - loss: 0.1226 - val_accuracy: 0.9480 - val_loss: 0.1220\n",
      "Epoch 16/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.1220 - val_accuracy: 0.9423 - val_loss: 0.1422\n",
      "Epoch 17/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1193 - val_accuracy: 0.9486 - val_loss: 0.1243\n",
      "Epoch 18/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9485 - loss: 0.1200 - val_accuracy: 0.9480 - val_loss: 0.1183\n",
      "Epoch 19/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1195 - val_accuracy: 0.9449 - val_loss: 0.1210\n",
      "Epoch 20/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 933us/step - accuracy: 0.9513 - loss: 0.1175 - val_accuracy: 0.9487 - val_loss: 0.1171\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 628us/step\n",
      "Acurácia: 0.9512474736323647\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# Definindo um otimizador com learning rate específica\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Criando o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo com o otimizador personalizado\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliando o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luize\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8277 - loss: 0.4112 - val_accuracy: 0.9063 - val_loss: 0.2374\n",
      "Epoch 2/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1000us/step - accuracy: 0.9102 - loss: 0.2274 - val_accuracy: 0.9211 - val_loss: 0.1957\n",
      "Epoch 3/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9235 - loss: 0.1947 - val_accuracy: 0.9289 - val_loss: 0.1785\n",
      "Epoch 4/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9297 - loss: 0.1771 - val_accuracy: 0.9331 - val_loss: 0.1648\n",
      "Epoch 5/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 993us/step - accuracy: 0.9349 - loss: 0.1641 - val_accuracy: 0.9352 - val_loss: 0.1574\n",
      "Epoch 6/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9362 - loss: 0.1571 - val_accuracy: 0.9380 - val_loss: 0.1508\n",
      "Epoch 7/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9383 - loss: 0.1488 - val_accuracy: 0.9387 - val_loss: 0.1478\n",
      "Epoch 8/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.1458 - val_accuracy: 0.9397 - val_loss: 0.1430\n",
      "Epoch 9/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 996us/step - accuracy: 0.9403 - loss: 0.1456 - val_accuracy: 0.9334 - val_loss: 0.1509\n",
      "Epoch 10/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 992us/step - accuracy: 0.9408 - loss: 0.1413 - val_accuracy: 0.9416 - val_loss: 0.1389\n",
      "Epoch 11/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 997us/step - accuracy: 0.9426 - loss: 0.1389 - val_accuracy: 0.9352 - val_loss: 0.1444\n",
      "Epoch 12/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9419 - loss: 0.1378 - val_accuracy: 0.9426 - val_loss: 0.1365\n",
      "Epoch 13/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.1366 - val_accuracy: 0.9417 - val_loss: 0.1431\n",
      "Epoch 14/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9433 - loss: 0.1365 - val_accuracy: 0.9427 - val_loss: 0.1330\n",
      "Epoch 15/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9435 - loss: 0.1327 - val_accuracy: 0.9404 - val_loss: 0.1346\n",
      "Epoch 16/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.1354 - val_accuracy: 0.9421 - val_loss: 0.1337\n",
      "Epoch 17/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.1320 - val_accuracy: 0.9442 - val_loss: 0.1357\n",
      "Epoch 18/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.1304 - val_accuracy: 0.9457 - val_loss: 0.1318\n",
      "Epoch 19/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9451 - loss: 0.1303 - val_accuracy: 0.9443 - val_loss: 0.1280\n",
      "Epoch 20/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.1294 - val_accuracy: 0.9427 - val_loss: 0.1374\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 704us/step\n",
      "Acurácia: 0.9440462643726966\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# Definindo um otimizador com learning rate específica\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Criando o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo com o otimizador personalizado\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliando o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chegamos a conclusão que 64 hidden layers é o numero ideal, agora vamos tentar mudar o batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luize\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8099 - loss: 0.4348 - val_accuracy: 0.8998 - val_loss: 0.2552\n",
      "Epoch 2/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9073 - loss: 0.2392 - val_accuracy: 0.9183 - val_loss: 0.2058\n",
      "Epoch 3/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9218 - loss: 0.1974 - val_accuracy: 0.9262 - val_loss: 0.1862\n",
      "Epoch 4/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9297 - loss: 0.1784 - val_accuracy: 0.9315 - val_loss: 0.1674\n",
      "Epoch 5/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9337 - loss: 0.1640 - val_accuracy: 0.9323 - val_loss: 0.1633\n",
      "Epoch 6/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9355 - loss: 0.1596 - val_accuracy: 0.9333 - val_loss: 0.1561\n",
      "Epoch 7/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9379 - loss: 0.1515 - val_accuracy: 0.9375 - val_loss: 0.1498\n",
      "Epoch 8/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9387 - loss: 0.1474 - val_accuracy: 0.9396 - val_loss: 0.1441\n",
      "Epoch 9/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9392 - loss: 0.1461 - val_accuracy: 0.9407 - val_loss: 0.1433\n",
      "Epoch 10/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9413 - loss: 0.1424 - val_accuracy: 0.9367 - val_loss: 0.1447\n",
      "Epoch 11/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.1387 - val_accuracy: 0.9412 - val_loss: 0.1423\n",
      "Epoch 12/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9434 - loss: 0.1347 - val_accuracy: 0.9416 - val_loss: 0.1402\n",
      "Epoch 13/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9426 - loss: 0.1353 - val_accuracy: 0.9415 - val_loss: 0.1333\n",
      "Epoch 14/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.1321 - val_accuracy: 0.9413 - val_loss: 0.1358\n",
      "Epoch 15/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.1304 - val_accuracy: 0.9456 - val_loss: 0.1304\n",
      "Epoch 16/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.1291 - val_accuracy: 0.9440 - val_loss: 0.1285\n",
      "Epoch 17/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.1291 - val_accuracy: 0.9419 - val_loss: 0.1377\n",
      "Epoch 18/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.1272 - val_accuracy: 0.9447 - val_loss: 0.1287\n",
      "Epoch 19/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.1269 - val_accuracy: 0.9454 - val_loss: 0.1290\n",
      "Epoch 20/20\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1243 - val_accuracy: 0.9463 - val_loss: 0.1246\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 799us/step\n",
      "Acurácia: 0.9480544846210024\n"
     ]
    }
   ],
   "source": [
    "# Definindo um otimizador com learning rate específica\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Criando o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo com o otimizador personalizado\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliando o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O batchsize maior não surtiu efeito, vamos tentar aumentar o numero de epocas mantendo esse batch size, qualquer coisa revertemos posteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luize\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8069 - loss: 0.4287 - val_accuracy: 0.9059 - val_loss: 0.2424\n",
      "Epoch 2/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9108 - loss: 0.2260 - val_accuracy: 0.9227 - val_loss: 0.1956\n",
      "Epoch 3/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.1892 - val_accuracy: 0.9300 - val_loss: 0.1768\n",
      "Epoch 4/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9298 - loss: 0.1744 - val_accuracy: 0.9315 - val_loss: 0.1661\n",
      "Epoch 5/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9332 - loss: 0.1623 - val_accuracy: 0.9372 - val_loss: 0.1526\n",
      "Epoch 6/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9395 - loss: 0.1486 - val_accuracy: 0.9319 - val_loss: 0.1549\n",
      "Epoch 7/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9380 - loss: 0.1479 - val_accuracy: 0.9412 - val_loss: 0.1431\n",
      "Epoch 8/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9407 - loss: 0.1427 - val_accuracy: 0.9410 - val_loss: 0.1386\n",
      "Epoch 9/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.1363 - val_accuracy: 0.9417 - val_loss: 0.1367\n",
      "Epoch 10/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.1341 - val_accuracy: 0.9430 - val_loss: 0.1347\n",
      "Epoch 11/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9442 - loss: 0.1341 - val_accuracy: 0.9417 - val_loss: 0.1379\n",
      "Epoch 12/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.1293 - val_accuracy: 0.9432 - val_loss: 0.1305\n",
      "Epoch 13/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.1294 - val_accuracy: 0.9444 - val_loss: 0.1284\n",
      "Epoch 14/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.1263 - val_accuracy: 0.9430 - val_loss: 0.1335\n",
      "Epoch 15/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9465 - loss: 0.1260 - val_accuracy: 0.9459 - val_loss: 0.1257\n",
      "Epoch 16/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9465 - loss: 0.1251 - val_accuracy: 0.9469 - val_loss: 0.1235\n",
      "Epoch 17/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9460 - loss: 0.1273 - val_accuracy: 0.9482 - val_loss: 0.1238\n",
      "Epoch 18/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.1227 - val_accuracy: 0.9476 - val_loss: 0.1230\n",
      "Epoch 19/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.1221 - val_accuracy: 0.9484 - val_loss: 0.1226\n",
      "Epoch 20/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1188 - val_accuracy: 0.9476 - val_loss: 0.1218\n",
      "Epoch 21/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9476 - loss: 0.1198 - val_accuracy: 0.9486 - val_loss: 0.1225\n",
      "Epoch 22/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9499 - loss: 0.1174 - val_accuracy: 0.9476 - val_loss: 0.1208\n",
      "Epoch 23/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.1169 - val_accuracy: 0.9443 - val_loss: 0.1238\n",
      "Epoch 24/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1164 - val_accuracy: 0.9478 - val_loss: 0.1210\n",
      "Epoch 25/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9497 - loss: 0.1171 - val_accuracy: 0.9493 - val_loss: 0.1183\n",
      "Epoch 26/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.1183 - val_accuracy: 0.9454 - val_loss: 0.1291\n",
      "Epoch 27/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9497 - loss: 0.1155 - val_accuracy: 0.9449 - val_loss: 0.1213\n",
      "Epoch 28/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1147 - val_accuracy: 0.9480 - val_loss: 0.1195\n",
      "Epoch 29/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 968us/step - accuracy: 0.9503 - loss: 0.1148 - val_accuracy: 0.9484 - val_loss: 0.1168\n",
      "Epoch 30/30\n",
      "\u001b[1m1380/1380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9510 - loss: 0.1140 - val_accuracy: 0.9468 - val_loss: 0.1172\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 643us/step\n",
      "Acurácia: 0.9495066152618081\n"
     ]
    }
   ],
   "source": [
    "# Definindo um otimizador com learning rate específica\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Criando o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo com o otimizador personalizado\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliando o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar esse mesmo número de epocas mas com batchsize de 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luize\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8386 - loss: 0.3925 - val_accuracy: 0.9128 - val_loss: 0.2171\n",
      "Epoch 2/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.2022 - val_accuracy: 0.9306 - val_loss: 0.1742\n",
      "Epoch 3/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.1750 - val_accuracy: 0.9344 - val_loss: 0.1584\n",
      "Epoch 4/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 974us/step - accuracy: 0.9356 - loss: 0.1588 - val_accuracy: 0.9359 - val_loss: 0.1557\n",
      "Epoch 5/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 949us/step - accuracy: 0.9386 - loss: 0.1492 - val_accuracy: 0.9394 - val_loss: 0.1436\n",
      "Epoch 6/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9394 - loss: 0.1450 - val_accuracy: 0.9396 - val_loss: 0.1451\n",
      "Epoch 7/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9421 - loss: 0.1389 - val_accuracy: 0.9423 - val_loss: 0.1365\n",
      "Epoch 8/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9425 - loss: 0.1392 - val_accuracy: 0.9435 - val_loss: 0.1328\n",
      "Epoch 9/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.1348 - val_accuracy: 0.9421 - val_loss: 0.1384\n",
      "Epoch 10/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9442 - loss: 0.1333 - val_accuracy: 0.9392 - val_loss: 0.1396\n",
      "Epoch 11/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 967us/step - accuracy: 0.9449 - loss: 0.1302 - val_accuracy: 0.9400 - val_loss: 0.1335\n",
      "Epoch 12/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.1283 - val_accuracy: 0.9470 - val_loss: 0.1273\n",
      "Epoch 13/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.1266 - val_accuracy: 0.9453 - val_loss: 0.1292\n",
      "Epoch 14/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1249 - val_accuracy: 0.9460 - val_loss: 0.1252\n",
      "Epoch 15/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1252 - val_accuracy: 0.9464 - val_loss: 0.1286\n",
      "Epoch 16/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9487 - loss: 0.1216 - val_accuracy: 0.9464 - val_loss: 0.1239\n",
      "Epoch 17/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.1226 - val_accuracy: 0.9460 - val_loss: 0.1237\n",
      "Epoch 18/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9484 - loss: 0.1213 - val_accuracy: 0.9440 - val_loss: 0.1244\n",
      "Epoch 19/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9478 - loss: 0.1222 - val_accuracy: 0.9479 - val_loss: 0.1221\n",
      "Epoch 20/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9499 - loss: 0.1183 - val_accuracy: 0.9407 - val_loss: 0.1276\n",
      "Epoch 21/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.1207 - val_accuracy: 0.9436 - val_loss: 0.1257\n",
      "Epoch 22/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.1207 - val_accuracy: 0.9484 - val_loss: 0.1227\n",
      "Epoch 23/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1192 - val_accuracy: 0.9484 - val_loss: 0.1188\n",
      "Epoch 24/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1161 - val_accuracy: 0.9477 - val_loss: 0.1218\n",
      "Epoch 25/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.1182 - val_accuracy: 0.9502 - val_loss: 0.1175\n",
      "Epoch 26/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9515 - loss: 0.1151 - val_accuracy: 0.9478 - val_loss: 0.1201\n",
      "Epoch 27/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1166 - val_accuracy: 0.9489 - val_loss: 0.1200\n",
      "Epoch 28/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9520 - loss: 0.1134 - val_accuracy: 0.9492 - val_loss: 0.1231\n",
      "Epoch 29/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1149 - val_accuracy: 0.9495 - val_loss: 0.1177\n",
      "Epoch 30/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1134 - val_accuracy: 0.9511 - val_loss: 0.1165\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 718us/step\n",
      "Acurácia: 0.9529968239949728\n"
     ]
    }
   ],
   "source": [
    "# Definindo um otimizador com learning rate específica\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Criando o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo com o otimizador personalizado\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliando o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos retornar para acuracia superior à 0.95\n",
    "Mantendo esses parametros vamos tentar usar 128 hidden layers com dropout de 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8399 - loss: 0.3810 - val_accuracy: 0.9123 - val_loss: 0.2145\n",
      "Epoch 2/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9152 - loss: 0.2129 - val_accuracy: 0.9302 - val_loss: 0.1759\n",
      "Epoch 3/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9251 - loss: 0.1833 - val_accuracy: 0.9363 - val_loss: 0.1584\n",
      "Epoch 4/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9322 - loss: 0.1648 - val_accuracy: 0.9371 - val_loss: 0.1460\n",
      "Epoch 5/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9352 - loss: 0.1562 - val_accuracy: 0.9408 - val_loss: 0.1407\n",
      "Epoch 6/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9386 - loss: 0.1468 - val_accuracy: 0.9397 - val_loss: 0.1378\n",
      "Epoch 7/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9397 - loss: 0.1437 - val_accuracy: 0.9408 - val_loss: 0.1379\n",
      "Epoch 8/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9421 - loss: 0.1397 - val_accuracy: 0.9427 - val_loss: 0.1326\n",
      "Epoch 9/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9410 - loss: 0.1392 - val_accuracy: 0.9455 - val_loss: 0.1283\n",
      "Epoch 10/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9419 - loss: 0.1375 - val_accuracy: 0.9445 - val_loss: 0.1317\n",
      "Epoch 11/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9442 - loss: 0.1332 - val_accuracy: 0.9426 - val_loss: 0.1298\n",
      "Epoch 12/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.1347 - val_accuracy: 0.9407 - val_loss: 0.1299\n",
      "Epoch 13/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9435 - loss: 0.1331 - val_accuracy: 0.9453 - val_loss: 0.1253\n",
      "Epoch 14/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.1318 - val_accuracy: 0.9443 - val_loss: 0.1245\n",
      "Epoch 15/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.1307 - val_accuracy: 0.9464 - val_loss: 0.1280\n",
      "Epoch 16/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.1302 - val_accuracy: 0.9451 - val_loss: 0.1236\n",
      "Epoch 17/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.1290 - val_accuracy: 0.9482 - val_loss: 0.1219\n",
      "Epoch 18/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.1283 - val_accuracy: 0.9460 - val_loss: 0.1216\n",
      "Epoch 19/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.1241 - val_accuracy: 0.9472 - val_loss: 0.1219\n",
      "Epoch 20/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.1267 - val_accuracy: 0.9422 - val_loss: 0.1261\n",
      "Epoch 21/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.1237 - val_accuracy: 0.9496 - val_loss: 0.1189\n",
      "Epoch 22/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.1255 - val_accuracy: 0.9489 - val_loss: 0.1225\n",
      "Epoch 23/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.1226 - val_accuracy: 0.9484 - val_loss: 0.1175\n",
      "Epoch 24/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1222 - val_accuracy: 0.9498 - val_loss: 0.1180\n",
      "Epoch 25/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.1203 - val_accuracy: 0.9490 - val_loss: 0.1212\n",
      "Epoch 26/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.1215 - val_accuracy: 0.9442 - val_loss: 0.1212\n",
      "Epoch 27/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.1196 - val_accuracy: 0.9504 - val_loss: 0.1159\n",
      "Epoch 28/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.1217 - val_accuracy: 0.9488 - val_loss: 0.1168\n",
      "Epoch 29/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1194 - val_accuracy: 0.9501 - val_loss: 0.1172\n",
      "Epoch 30/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9469 - loss: 0.1219 - val_accuracy: 0.9482 - val_loss: 0.1177\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 830us/step\n",
      "Acurácia: 0.9511965216800558\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# Definindo um otimizador com learning rate específica\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Criando o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo com o otimizador personalizado\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliando o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado com dropout e numero elevado de hidden layers não se pagou, como no teste anterior a esse, a acuracia mudou muito pouco durante muitas epocas, vamos retornar à 64 camadas mas tentar incluir um dropout de 20% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luize\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8161 - loss: 0.4155 - val_accuracy: 0.9058 - val_loss: 0.2315\n",
      "Epoch 2/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9064 - loss: 0.2368 - val_accuracy: 0.9238 - val_loss: 0.1951\n",
      "Epoch 3/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9205 - loss: 0.2000 - val_accuracy: 0.9287 - val_loss: 0.1740\n",
      "Epoch 4/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9281 - loss: 0.1782 - val_accuracy: 0.9325 - val_loss: 0.1621\n",
      "Epoch 5/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.1694 - val_accuracy: 0.9377 - val_loss: 0.1503\n",
      "Epoch 6/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9342 - loss: 0.1596 - val_accuracy: 0.9401 - val_loss: 0.1419\n",
      "Epoch 7/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9371 - loss: 0.1535 - val_accuracy: 0.9411 - val_loss: 0.1405\n",
      "Epoch 8/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9359 - loss: 0.1538 - val_accuracy: 0.9419 - val_loss: 0.1377\n",
      "Epoch 9/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9376 - loss: 0.1492 - val_accuracy: 0.9423 - val_loss: 0.1337\n",
      "Epoch 10/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9399 - loss: 0.1426 - val_accuracy: 0.9438 - val_loss: 0.1320\n",
      "Epoch 11/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.1449 - val_accuracy: 0.9441 - val_loss: 0.1315\n",
      "Epoch 12/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9407 - loss: 0.1410 - val_accuracy: 0.9423 - val_loss: 0.1308\n",
      "Epoch 13/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.1376 - val_accuracy: 0.9459 - val_loss: 0.1297\n",
      "Epoch 14/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9422 - loss: 0.1369 - val_accuracy: 0.9444 - val_loss: 0.1332\n",
      "Epoch 15/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.1383 - val_accuracy: 0.9439 - val_loss: 0.1278\n",
      "Epoch 16/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9435 - loss: 0.1364 - val_accuracy: 0.9463 - val_loss: 0.1289\n",
      "Epoch 17/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.1337 - val_accuracy: 0.9457 - val_loss: 0.1290\n",
      "Epoch 18/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9407 - loss: 0.1376 - val_accuracy: 0.9443 - val_loss: 0.1274\n",
      "Epoch 19/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9442 - loss: 0.1314 - val_accuracy: 0.9472 - val_loss: 0.1282\n",
      "Epoch 20/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.1322 - val_accuracy: 0.9468 - val_loss: 0.1264\n",
      "Epoch 21/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9441 - loss: 0.1323 - val_accuracy: 0.9493 - val_loss: 0.1241\n",
      "Epoch 22/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.1296 - val_accuracy: 0.9479 - val_loss: 0.1220\n",
      "Epoch 23/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.1348 - val_accuracy: 0.9487 - val_loss: 0.1213\n",
      "Epoch 24/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9445 - loss: 0.1321 - val_accuracy: 0.9490 - val_loss: 0.1235\n",
      "Epoch 25/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.1287 - val_accuracy: 0.9480 - val_loss: 0.1248\n",
      "Epoch 26/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.1294 - val_accuracy: 0.9453 - val_loss: 0.1241\n",
      "Epoch 27/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.1292 - val_accuracy: 0.9488 - val_loss: 0.1213\n",
      "Epoch 28/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9451 - loss: 0.1278 - val_accuracy: 0.9494 - val_loss: 0.1206\n",
      "Epoch 29/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.1296 - val_accuracy: 0.9467 - val_loss: 0.1277\n",
      "Epoch 30/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.1275 - val_accuracy: 0.9469 - val_loss: 0.1221\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 697us/step\n",
      "Acurácia: 0.9500501027531039\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# Definindo um otimizador com learning rate específica\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Criando o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo com o otimizador personalizado\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliando o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais uma vez passou muito tempo com a acuracia muito parecida, vamos tentar diminuir o numero de epocas com esses mesmos parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luize\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8077 - loss: 0.4281 - val_accuracy: 0.9061 - val_loss: 0.2295\n",
      "Epoch 2/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9094 - loss: 0.2277 - val_accuracy: 0.9247 - val_loss: 0.1889\n",
      "Epoch 3/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9229 - loss: 0.1915 - val_accuracy: 0.9320 - val_loss: 0.1667\n",
      "Epoch 4/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9301 - loss: 0.1729 - val_accuracy: 0.9367 - val_loss: 0.1555\n",
      "Epoch 5/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9324 - loss: 0.1645 - val_accuracy: 0.9384 - val_loss: 0.1446\n",
      "Epoch 6/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9361 - loss: 0.1547 - val_accuracy: 0.9389 - val_loss: 0.1425\n",
      "Epoch 7/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9358 - loss: 0.1524 - val_accuracy: 0.9413 - val_loss: 0.1381\n",
      "Epoch 8/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9367 - loss: 0.1509 - val_accuracy: 0.9411 - val_loss: 0.1374\n",
      "Epoch 9/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9399 - loss: 0.1442 - val_accuracy: 0.9411 - val_loss: 0.1356\n",
      "Epoch 10/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9400 - loss: 0.1426 - val_accuracy: 0.9423 - val_loss: 0.1335\n",
      "Epoch 11/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9417 - loss: 0.1416 - val_accuracy: 0.9406 - val_loss: 0.1326\n",
      "Epoch 12/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9432 - loss: 0.1365 - val_accuracy: 0.9457 - val_loss: 0.1283\n",
      "Epoch 13/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9425 - loss: 0.1378 - val_accuracy: 0.9467 - val_loss: 0.1283\n",
      "Epoch 14/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.1353 - val_accuracy: 0.9465 - val_loss: 0.1252\n",
      "Epoch 15/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.1334 - val_accuracy: 0.9464 - val_loss: 0.1252\n",
      "Epoch 16/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9425 - loss: 0.1355 - val_accuracy: 0.9457 - val_loss: 0.1259\n",
      "Epoch 17/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9442 - loss: 0.1337 - val_accuracy: 0.9449 - val_loss: 0.1266\n",
      "Epoch 18/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.1317 - val_accuracy: 0.9472 - val_loss: 0.1260\n",
      "Epoch 19/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.1307 - val_accuracy: 0.9471 - val_loss: 0.1244\n",
      "Epoch 20/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9452 - loss: 0.1333 - val_accuracy: 0.9480 - val_loss: 0.1227\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 671us/step\n",
      "Acurácia: 0.9507804140695324\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# Definindo um otimizador com learning rate específica\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Criando o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo com o otimizador personalizado\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliando o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dropout não se pagou, o menor número de épocas foi bom pois conseguimos manter o resultado poupando esforço computacional. Vamos tentar com nosso melhor modelo, diminuir a learning rate e dobrar o número de épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luize\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8153 - loss: 0.4388 - val_accuracy: 0.8952 - val_loss: 0.2622\n",
      "Epoch 2/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9042 - loss: 0.2457 - val_accuracy: 0.9139 - val_loss: 0.2118\n",
      "Epoch 3/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9177 - loss: 0.2060 - val_accuracy: 0.9233 - val_loss: 0.1933\n",
      "Epoch 4/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.1864 - val_accuracy: 0.9314 - val_loss: 0.1748\n",
      "Epoch 5/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9302 - loss: 0.1764 - val_accuracy: 0.9326 - val_loss: 0.1651\n",
      "Epoch 6/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9352 - loss: 0.1632 - val_accuracy: 0.9314 - val_loss: 0.1623\n",
      "Epoch 7/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9363 - loss: 0.1564 - val_accuracy: 0.9345 - val_loss: 0.1543\n",
      "Epoch 8/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9382 - loss: 0.1494 - val_accuracy: 0.9360 - val_loss: 0.1505\n",
      "Epoch 9/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9376 - loss: 0.1503 - val_accuracy: 0.9383 - val_loss: 0.1450\n",
      "Epoch 10/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.1447 - val_accuracy: 0.9395 - val_loss: 0.1444\n",
      "Epoch 11/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.1415 - val_accuracy: 0.9413 - val_loss: 0.1402\n",
      "Epoch 12/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9425 - loss: 0.1385 - val_accuracy: 0.9417 - val_loss: 0.1370\n",
      "Epoch 13/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9417 - loss: 0.1387 - val_accuracy: 0.9366 - val_loss: 0.1437\n",
      "Epoch 14/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9435 - loss: 0.1368 - val_accuracy: 0.9434 - val_loss: 0.1362\n",
      "Epoch 15/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9431 - loss: 0.1364 - val_accuracy: 0.9426 - val_loss: 0.1351\n",
      "Epoch 16/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.1338 - val_accuracy: 0.9440 - val_loss: 0.1320\n",
      "Epoch 17/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.1311 - val_accuracy: 0.9431 - val_loss: 0.1314\n",
      "Epoch 18/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.1311 - val_accuracy: 0.9448 - val_loss: 0.1298\n",
      "Epoch 19/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 951us/step - accuracy: 0.9455 - loss: 0.1286 - val_accuracy: 0.9455 - val_loss: 0.1347\n",
      "Epoch 20/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.1288 - val_accuracy: 0.9415 - val_loss: 0.1306\n",
      "Epoch 21/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.1298 - val_accuracy: 0.9449 - val_loss: 0.1277\n",
      "Epoch 22/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 929us/step - accuracy: 0.9457 - loss: 0.1271 - val_accuracy: 0.9453 - val_loss: 0.1296\n",
      "Epoch 23/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1000us/step - accuracy: 0.9471 - loss: 0.1255 - val_accuracy: 0.9419 - val_loss: 0.1310\n",
      "Epoch 24/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.1264 - val_accuracy: 0.9460 - val_loss: 0.1265\n",
      "Epoch 25/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 926us/step - accuracy: 0.9466 - loss: 0.1260 - val_accuracy: 0.9456 - val_loss: 0.1285\n",
      "Epoch 26/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 945us/step - accuracy: 0.9475 - loss: 0.1238 - val_accuracy: 0.9458 - val_loss: 0.1252\n",
      "Epoch 27/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9485 - loss: 0.1229 - val_accuracy: 0.9412 - val_loss: 0.1313\n",
      "Epoch 28/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 972us/step - accuracy: 0.9470 - loss: 0.1250 - val_accuracy: 0.9458 - val_loss: 0.1246\n",
      "Epoch 29/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 945us/step - accuracy: 0.9473 - loss: 0.1243 - val_accuracy: 0.9448 - val_loss: 0.1249\n",
      "Epoch 30/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 980us/step - accuracy: 0.9482 - loss: 0.1236 - val_accuracy: 0.9453 - val_loss: 0.1270\n",
      "Epoch 31/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 994us/step - accuracy: 0.9477 - loss: 0.1233 - val_accuracy: 0.9475 - val_loss: 0.1249\n",
      "Epoch 32/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1182 - val_accuracy: 0.9476 - val_loss: 0.1234\n",
      "Epoch 33/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 953us/step - accuracy: 0.9487 - loss: 0.1208 - val_accuracy: 0.9480 - val_loss: 0.1214\n",
      "Epoch 34/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9499 - loss: 0.1205 - val_accuracy: 0.9483 - val_loss: 0.1223\n",
      "Epoch 35/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1210 - val_accuracy: 0.9481 - val_loss: 0.1206\n",
      "Epoch 36/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9498 - loss: 0.1198 - val_accuracy: 0.9480 - val_loss: 0.1220\n",
      "Epoch 37/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 995us/step - accuracy: 0.9481 - loss: 0.1206 - val_accuracy: 0.9468 - val_loss: 0.1229\n",
      "Epoch 38/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1193 - val_accuracy: 0.9485 - val_loss: 0.1204\n",
      "Epoch 39/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9490 - loss: 0.1191 - val_accuracy: 0.9484 - val_loss: 0.1199\n",
      "Epoch 40/40\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9505 - loss: 0.1173 - val_accuracy: 0.9468 - val_loss: 0.1204\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 674us/step\n",
      "Acurácia: 0.9493877273730872\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# Definindo um otimizador com learning rate específica\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "# Criando o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo com o otimizador personalizado\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train, epochs=40, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliando o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talvez o número de épocas tenha sido pouco para essa learning rate, visto que ela foi aumentando a acuracia aos poucos, vamos então aumentar para 60 épocas e adicionar um dropout para evitar overfiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luize\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.7747 - loss: 0.4779 - val_accuracy: 0.8763 - val_loss: 0.2987\n",
      "Epoch 2/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.8892 - loss: 0.2800 - val_accuracy: 0.9093 - val_loss: 0.2257\n",
      "Epoch 3/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9072 - loss: 0.2308 - val_accuracy: 0.9210 - val_loss: 0.1968\n",
      "Epoch 4/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9182 - loss: 0.2026 - val_accuracy: 0.9280 - val_loss: 0.1810\n",
      "Epoch 5/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9234 - loss: 0.1912 - val_accuracy: 0.9329 - val_loss: 0.1678\n",
      "Epoch 6/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.1775 - val_accuracy: 0.9351 - val_loss: 0.1594\n",
      "Epoch 7/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9330 - loss: 0.1674 - val_accuracy: 0.9370 - val_loss: 0.1532\n",
      "Epoch 8/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9323 - loss: 0.1622 - val_accuracy: 0.9374 - val_loss: 0.1492\n",
      "Epoch 9/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9348 - loss: 0.1575 - val_accuracy: 0.9393 - val_loss: 0.1446\n",
      "Epoch 10/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9366 - loss: 0.1542 - val_accuracy: 0.9397 - val_loss: 0.1437\n",
      "Epoch 11/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9392 - loss: 0.1488 - val_accuracy: 0.9410 - val_loss: 0.1402\n",
      "Epoch 12/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9349 - loss: 0.1512 - val_accuracy: 0.9421 - val_loss: 0.1372\n",
      "Epoch 13/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9386 - loss: 0.1467 - val_accuracy: 0.9435 - val_loss: 0.1339\n",
      "Epoch 14/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9400 - loss: 0.1427 - val_accuracy: 0.9436 - val_loss: 0.1330\n",
      "Epoch 15/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9402 - loss: 0.1421 - val_accuracy: 0.9449 - val_loss: 0.1340\n",
      "Epoch 16/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9423 - loss: 0.1387 - val_accuracy: 0.9442 - val_loss: 0.1327\n",
      "Epoch 17/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9422 - loss: 0.1392 - val_accuracy: 0.9457 - val_loss: 0.1285\n",
      "Epoch 18/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.1368 - val_accuracy: 0.9456 - val_loss: 0.1287\n",
      "Epoch 19/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.1359 - val_accuracy: 0.9477 - val_loss: 0.1278\n",
      "Epoch 20/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9442 - loss: 0.1356 - val_accuracy: 0.9450 - val_loss: 0.1272\n",
      "Epoch 21/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9428 - loss: 0.1362 - val_accuracy: 0.9463 - val_loss: 0.1264\n",
      "Epoch 22/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.1343 - val_accuracy: 0.9469 - val_loss: 0.1250\n",
      "Epoch 23/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9451 - loss: 0.1319 - val_accuracy: 0.9470 - val_loss: 0.1257\n",
      "Epoch 24/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9450 - loss: 0.1312 - val_accuracy: 0.9475 - val_loss: 0.1241\n",
      "Epoch 25/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.1321 - val_accuracy: 0.9489 - val_loss: 0.1226\n",
      "Epoch 26/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.1298 - val_accuracy: 0.9460 - val_loss: 0.1228\n",
      "Epoch 27/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.1311 - val_accuracy: 0.9490 - val_loss: 0.1227\n",
      "Epoch 28/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.1313 - val_accuracy: 0.9488 - val_loss: 0.1244\n",
      "Epoch 29/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.1294 - val_accuracy: 0.9482 - val_loss: 0.1213\n",
      "Epoch 30/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.1291 - val_accuracy: 0.9480 - val_loss: 0.1217\n",
      "Epoch 31/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.1295 - val_accuracy: 0.9470 - val_loss: 0.1228\n",
      "Epoch 32/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.1289 - val_accuracy: 0.9479 - val_loss: 0.1219\n",
      "Epoch 33/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.1256 - val_accuracy: 0.9484 - val_loss: 0.1215\n",
      "Epoch 34/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.1289 - val_accuracy: 0.9485 - val_loss: 0.1211\n",
      "Epoch 35/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 991us/step - accuracy: 0.9467 - loss: 0.1253 - val_accuracy: 0.9479 - val_loss: 0.1207\n",
      "Epoch 36/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9469 - loss: 0.1267 - val_accuracy: 0.9459 - val_loss: 0.1224\n",
      "Epoch 37/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.1281 - val_accuracy: 0.9486 - val_loss: 0.1203\n",
      "Epoch 38/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 982us/step - accuracy: 0.9457 - loss: 0.1291 - val_accuracy: 0.9485 - val_loss: 0.1250\n",
      "Epoch 39/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.1249 - val_accuracy: 0.9498 - val_loss: 0.1194\n",
      "Epoch 40/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.1245 - val_accuracy: 0.9494 - val_loss: 0.1186\n",
      "Epoch 41/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.1271 - val_accuracy: 0.9486 - val_loss: 0.1204\n",
      "Epoch 42/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.1258 - val_accuracy: 0.9495 - val_loss: 0.1194\n",
      "Epoch 43/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9484 - loss: 0.1243 - val_accuracy: 0.9479 - val_loss: 0.1198\n",
      "Epoch 44/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.1248 - val_accuracy: 0.9504 - val_loss: 0.1194\n",
      "Epoch 45/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.1253 - val_accuracy: 0.9480 - val_loss: 0.1193\n",
      "Epoch 46/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9479 - loss: 0.1224 - val_accuracy: 0.9497 - val_loss: 0.1186\n",
      "Epoch 47/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9479 - loss: 0.1238 - val_accuracy: 0.9491 - val_loss: 0.1202\n",
      "Epoch 48/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9482 - loss: 0.1221 - val_accuracy: 0.9502 - val_loss: 0.1189\n",
      "Epoch 49/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 978us/step - accuracy: 0.9475 - loss: 0.1244 - val_accuracy: 0.9497 - val_loss: 0.1178\n",
      "Epoch 50/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.1223 - val_accuracy: 0.9502 - val_loss: 0.1178\n",
      "Epoch 51/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9479 - loss: 0.1240 - val_accuracy: 0.9498 - val_loss: 0.1178\n",
      "Epoch 52/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.1209 - val_accuracy: 0.9503 - val_loss: 0.1175\n",
      "Epoch 53/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 991us/step - accuracy: 0.9476 - loss: 0.1221 - val_accuracy: 0.9501 - val_loss: 0.1189\n",
      "Epoch 54/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9484 - loss: 0.1236 - val_accuracy: 0.9499 - val_loss: 0.1174\n",
      "Epoch 55/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9484 - loss: 0.1217 - val_accuracy: 0.9514 - val_loss: 0.1168\n",
      "Epoch 56/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.1223 - val_accuracy: 0.9482 - val_loss: 0.1231\n",
      "Epoch 57/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1216 - val_accuracy: 0.9502 - val_loss: 0.1173\n",
      "Epoch 58/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1236 - val_accuracy: 0.9487 - val_loss: 0.1178\n",
      "Epoch 59/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9487 - loss: 0.1214 - val_accuracy: 0.9492 - val_loss: 0.1182\n",
      "Epoch 60/60\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9476 - loss: 0.1218 - val_accuracy: 0.9497 - val_loss: 0.1183\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 664us/step\n",
      "Acurácia: 0.9524957964639346\n"
     ]
    }
   ],
   "source": [
    "# Definindo um otimizador com learning rate específica\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "# Criando o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo com o otimizador personalizado\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train, epochs=60, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliando o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos aumentar ainda mais a acuracia final, porém desde a época 13 ate à época 60 a diferença foi muito pouca, vou tentar então voltar ao número anterior de learning rate e agora vou tentar adicionar outra camada oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luize\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8541 - loss: 0.3384 - val_accuracy: 0.9292 - val_loss: 0.1730\n",
      "Epoch 2/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9291 - loss: 0.1721 - val_accuracy: 0.9332 - val_loss: 0.1565\n",
      "Epoch 3/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9357 - loss: 0.1513 - val_accuracy: 0.9401 - val_loss: 0.1435\n",
      "Epoch 4/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9389 - loss: 0.1426 - val_accuracy: 0.9424 - val_loss: 0.1384\n",
      "Epoch 5/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9416 - loss: 0.1361 - val_accuracy: 0.9358 - val_loss: 0.1358\n",
      "Epoch 6/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.1315 - val_accuracy: 0.9461 - val_loss: 0.1244\n",
      "Epoch 7/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9463 - loss: 0.1258 - val_accuracy: 0.9466 - val_loss: 0.1239\n",
      "Epoch 8/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.1236 - val_accuracy: 0.9427 - val_loss: 0.1256\n",
      "Epoch 9/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1204 - val_accuracy: 0.9361 - val_loss: 0.1339\n",
      "Epoch 10/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.1188 - val_accuracy: 0.9487 - val_loss: 0.1166\n",
      "Epoch 11/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9485 - loss: 0.1159 - val_accuracy: 0.9451 - val_loss: 0.1246\n",
      "Epoch 12/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1146 - val_accuracy: 0.9458 - val_loss: 0.1233\n",
      "Epoch 13/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9512 - loss: 0.1123 - val_accuracy: 0.9443 - val_loss: 0.1179\n",
      "Epoch 14/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9518 - loss: 0.1110 - val_accuracy: 0.9504 - val_loss: 0.1115\n",
      "Epoch 15/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1097 - val_accuracy: 0.9503 - val_loss: 0.1143\n",
      "Epoch 16/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9529 - loss: 0.1087 - val_accuracy: 0.9490 - val_loss: 0.1144\n",
      "Epoch 17/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9522 - loss: 0.1093 - val_accuracy: 0.9414 - val_loss: 0.1252\n",
      "Epoch 18/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9525 - loss: 0.1074 - val_accuracy: 0.9507 - val_loss: 0.1094\n",
      "Epoch 19/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9524 - loss: 0.1084 - val_accuracy: 0.9488 - val_loss: 0.1171\n",
      "Epoch 20/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9537 - loss: 0.1058 - val_accuracy: 0.9512 - val_loss: 0.1096\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 774us/step\n",
      "Acurácia: 0.955332121809134\n"
     ]
    }
   ],
   "source": [
    "# Definindo um otimizador com learning rate específica\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Criando o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=32, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo com o otimizador personalizado\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliando o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos o melhor resultado até agora, vamos tentar adicionar mais uma camada oculta para ver se mantemos a melhoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luize\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.8732 - loss: 0.2986 - val_accuracy: 0.9011 - val_loss: 0.2245\n",
      "Epoch 2/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9334 - loss: 0.1570 - val_accuracy: 0.9423 - val_loss: 0.1325\n",
      "Epoch 3/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.1359 - val_accuracy: 0.9453 - val_loss: 0.1279\n",
      "Epoch 4/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.1256 - val_accuracy: 0.9463 - val_loss: 0.1247\n",
      "Epoch 5/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.1200 - val_accuracy: 0.9424 - val_loss: 0.1304\n",
      "Epoch 6/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.1141 - val_accuracy: 0.9506 - val_loss: 0.1095\n",
      "Epoch 7/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9525 - loss: 0.1078 - val_accuracy: 0.9482 - val_loss: 0.1186\n",
      "Epoch 8/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1049 - val_accuracy: 0.9490 - val_loss: 0.1094\n",
      "Epoch 9/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9548 - loss: 0.1032 - val_accuracy: 0.9531 - val_loss: 0.1038\n",
      "Epoch 10/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9553 - loss: 0.1020 - val_accuracy: 0.9521 - val_loss: 0.1109\n",
      "Epoch 11/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9554 - loss: 0.1003 - val_accuracy: 0.9536 - val_loss: 0.1039\n",
      "Epoch 12/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9561 - loss: 0.0989 - val_accuracy: 0.9535 - val_loss: 0.1099\n",
      "Epoch 13/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9568 - loss: 0.0967 - val_accuracy: 0.9556 - val_loss: 0.1043\n",
      "Epoch 14/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9570 - loss: 0.0960 - val_accuracy: 0.9519 - val_loss: 0.1083\n",
      "Epoch 15/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.0932 - val_accuracy: 0.9524 - val_loss: 0.1063\n",
      "Epoch 16/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9590 - loss: 0.0924 - val_accuracy: 0.9560 - val_loss: 0.1009\n",
      "Epoch 17/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9585 - loss: 0.0928 - val_accuracy: 0.9536 - val_loss: 0.1032\n",
      "Epoch 18/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9594 - loss: 0.0902 - val_accuracy: 0.9534 - val_loss: 0.1020\n",
      "Epoch 19/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.0901 - val_accuracy: 0.9554 - val_loss: 0.1073\n",
      "Epoch 20/20\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9604 - loss: 0.0882 - val_accuracy: 0.9525 - val_loss: 0.1031\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 916us/step\n",
      "Acurácia: 0.9590940742879465\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Criando o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo com o otimizador personalizado\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliando o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos melhorar mais uma vez, vou testar esse mesmo modelo mas com 30 épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luize\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8671 - loss: 0.3128 - val_accuracy: 0.9310 - val_loss: 0.1656\n",
      "Epoch 2/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9328 - loss: 0.1588 - val_accuracy: 0.9345 - val_loss: 0.1497\n",
      "Epoch 3/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9393 - loss: 0.1411 - val_accuracy: 0.9417 - val_loss: 0.1292\n",
      "Epoch 4/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9428 - loss: 0.1316 - val_accuracy: 0.9480 - val_loss: 0.1262\n",
      "Epoch 5/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.1243 - val_accuracy: 0.9481 - val_loss: 0.1151\n",
      "Epoch 6/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1197 - val_accuracy: 0.9487 - val_loss: 0.1163\n",
      "Epoch 7/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9519 - loss: 0.1128 - val_accuracy: 0.9494 - val_loss: 0.1144\n",
      "Epoch 8/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.1111 - val_accuracy: 0.9515 - val_loss: 0.1102\n",
      "Epoch 9/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9542 - loss: 0.1070 - val_accuracy: 0.9455 - val_loss: 0.1145\n",
      "Epoch 10/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9518 - loss: 0.1081 - val_accuracy: 0.9513 - val_loss: 0.1063\n",
      "Epoch 11/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9542 - loss: 0.1017 - val_accuracy: 0.9524 - val_loss: 0.1069\n",
      "Epoch 12/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9544 - loss: 0.1024 - val_accuracy: 0.9527 - val_loss: 0.1061\n",
      "Epoch 13/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9547 - loss: 0.1017 - val_accuracy: 0.9528 - val_loss: 0.1046\n",
      "Epoch 14/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9562 - loss: 0.0991 - val_accuracy: 0.9523 - val_loss: 0.1068\n",
      "Epoch 15/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9561 - loss: 0.0986 - val_accuracy: 0.9523 - val_loss: 0.1075\n",
      "Epoch 16/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9569 - loss: 0.0967 - val_accuracy: 0.9536 - val_loss: 0.1037\n",
      "Epoch 17/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9569 - loss: 0.0950 - val_accuracy: 0.9497 - val_loss: 0.1066\n",
      "Epoch 18/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9592 - loss: 0.0912 - val_accuracy: 0.9542 - val_loss: 0.1023\n",
      "Epoch 19/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9607 - loss: 0.0890 - val_accuracy: 0.9545 - val_loss: 0.1059\n",
      "Epoch 20/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9592 - loss: 0.0909 - val_accuracy: 0.9534 - val_loss: 0.1080\n",
      "Epoch 21/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.0924 - val_accuracy: 0.9551 - val_loss: 0.1036\n",
      "Epoch 22/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.0896 - val_accuracy: 0.9531 - val_loss: 0.1039\n",
      "Epoch 23/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9605 - loss: 0.0891 - val_accuracy: 0.9502 - val_loss: 0.1172\n",
      "Epoch 24/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9604 - loss: 0.0890 - val_accuracy: 0.9562 - val_loss: 0.1016\n",
      "Epoch 25/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9612 - loss: 0.0869 - val_accuracy: 0.9562 - val_loss: 0.1035\n",
      "Epoch 26/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9617 - loss: 0.0853 - val_accuracy: 0.9554 - val_loss: 0.1006\n",
      "Epoch 27/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9615 - loss: 0.0857 - val_accuracy: 0.9531 - val_loss: 0.1122\n",
      "Epoch 28/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9610 - loss: 0.0877 - val_accuracy: 0.9532 - val_loss: 0.1090\n",
      "Epoch 29/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9623 - loss: 0.0832 - val_accuracy: 0.9543 - val_loss: 0.1043\n",
      "Epoch 30/30\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9629 - loss: 0.0830 - val_accuracy: 0.9538 - val_loss: 0.1056\n",
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 750us/step\n",
      "Acurácia: 0.9618200037364765\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Criando o modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilando o modelo com o otimizador personalizado\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Avaliando o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos chegar num resultado ótimo, vamos plotar gráficos para entender melhor os nossos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 777us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "cm = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "# Plotando a matriz de confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            annot_kws={'fontsize': 14}, linewidths=0.5)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3680/3680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 729us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS Statistic: 0.92\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Calculando a curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Calculando a estatística KS\n",
    "ks_statistic = np.max(tpr - fpr)\n",
    "ks_idx = np.argmax(tpr - fpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='True Positive Rate (TPR)')\n",
    "plt.plot(fpr, fpr, label='False Positive Rate (FPR)')\n",
    "plt.plot([fpr[ks_idx]], [tpr[ks_idx]], marker='o', markersize=5, color=\"red\")\n",
    "plt.text(fpr[ks_idx], tpr[ks_idx], f'KS={ks_statistic:.2f}', fontsize=12, verticalalignment='top')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('Rate')\n",
    "plt.title('Kolmogorov-Smirnov (KS) Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "print(f\"KS Statistic: {ks_statistic:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
